# Portofolio ADS minor
### Name: Jesse de lange
### Student number: 19043856

In this portofolio, I will show the progress I made dureing the minor Applied Data Science. During this minor I worked on two different projects:
* FoodBoost
* Cofano Containers

# <a id="contents"></a>Contents <!-- omit in toc -->
- [Individual tasks and reflection](#contents)
  - [Datacamp certificates](#datacamp-certificates)
  - [Personel contribution to the projects](#personel-contribution-to-the-projects)
  - [Evaluation on group](#evaluation-on-group)
  - 

# <a id="datacamp-certificates"></a>Datacamp certificates <!-- omit in toc -->
* Introduction to Python  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/a0454797c8ede86d8947317d151dad4d9d4b299f)
* Intermediate Python  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/7a84a520e49f07fe34c1c0b7767571c11474e03e)
* Python Data Science Toolbox (Part 1)  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/8546b0726b05a5924b7009e0f7a21a82bd4aeeb9)
* Python Data Science Toolbox (Part 2)  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/a323174cd6733c99b8e29fa1d6146ec78b97aa19)
* Statistical Thinking in Python (Part 1)   
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/30e13c3a36703968b529f889e7cc07c2b58426da)
* Machine Learning with scikit-learn  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/50cec0549b023167f8bcf6792666701bbf7cbfd9)
* Linear Classifiers in Python  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/8ebed405edf024f626b5b59d3a9b0ad77c9dbbf6)
* Introduction to Data Visualization with Matplotlib  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/707520704347d75821c06d39cdae920f70a0ce3d)
* Model Validation in Python  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/d5cfc3fda5c53e3b45644f2943ce79689fe77025)
* Data Manipulation with pandas  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/205a301957630cea15c1d3736de7277bb8420666)
* Exploratory Data Analysis in Python  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/4aa6f96f4f810ec86df8f51fb2c00712cdb61a42)
* Cleaning Data in Python  
  [Certificate](https://www.datacamp.com/statement-of-accomplishment/course/cab5e798e60d4761baedec98cb38b88ba5152e02)  
  
## <a id="personel-contribution-to-the-projects"></a>Personel contribution to the projects 
At the beginning of this minor first tried to connect and bond with the group as much as possible to come up with a specific role for me.
Overall it was easy to bond with the group since everybody over open about there weaknesses and strength.

During the Foodboost project I definitly wanted to contribute to the project with a mathematical part for the project. So I came up with an
Linear Programming model to scedule every predicted meal based on the prediction system the group had made. This model filled in the scedule based on a maximum 
amount of calories and separate predicted lists for meals and dinners. For the maximum amount of calories I contributed a little bit to the research
so we knew what would be the maximum amount of calories for the Linear Programming model.

For the COFANO project I mainly was focussing on collecting knowledge about reinforcement lreaning. I did this using Youtube tutorials and documentation of
different libraries needed. This way I could provide usefull knowledge to the team so they could make convincing choices during the making of the final model. I also could share this knowledge with other research groups of the minor. Below I will reflect on the making of my own reinforcement learning model.  

### **Making a reinforcement learning model by myself** 
#### **Situation** 
To gain knowlegde bout reinforcement learning and contribute to the project, we all had to make a reinforcement learning model by our own from scratch with our own unique method.  

#### **Tast** 
My task was to make an reinforcement learning model using a [tutorial] I found on youtube, with the nessecary [documentation].  

#### **Action**
I watched the whole 3 hour tutorial on youtube to gain information about the used library. Then I made a custom environment on a easy problem that was demonstrated 
in the Youtube tutorial. At last I changed the model to fit he COFANO problem.  

#### **Result**
The result of my work was a working model that could place containers on places where there was no container. Also I gained very much knowledge about the used
library. This was of great value to the work of my teammates and other groups of the minor.  

#### **Reflection**
I am glad that I made a working model that could place containers on empty spaced. The only thing I regret was nog really making an al tweakable agent where
I could finetune the model even further.  

## <a id="personel-learning-objectives"></a>Personel learning objectives
When I started with the minor, I realy wanted to get an introduction to machine learning and neural networks and how to use them in diffenet situations.
I always was very drawn to the concept of machine learning en neural networks like making predictions, self training computers and recognition. for around half a year I had a book where looked into once in a while, but I had no experience what so ever.

During this minor I definitely learnied a lot of things about machine learning and neural networks. I learned the basics of fitting and defining a model, data cleaning/preperation and background knowledge of how such models work. I am also glad that I can do all of this without or with minimal help and use them for my own projects at home or later at work. Below I will reflect on hyperparametertuning the model.  

### **Hyperparametertuning the used model** 
#### **Situation** 
The group made a model and wanted to optimize the results so hyperparameter tuning was needed to make sure all the parameters where correctly defined.

#### **Tast** 
Using a study, my tast was to find the optimal hypermarameter settings using the optuna hyperparameter tuning method.

#### **Action**
The first thing I did was following machine learning lessons of the fourth year of my study. In the lessons, different methods of hyperparametertuning where explained and I tried them out for myself so I could get a better undertanding of the optuna library and how to use it. Then when I had enough information, I applied the method to our model and used it to optimize the results.

#### **Result**
At the end, we got the right hyperparameters and the model eventually worked a little bit better.

#### **Reflection**
It maybe felt like cheating but I was glad that I followed the lectures of my study. This way I gained a lot of knowledge about how the hyperparameters influence the model and how I could optimize them to my demand.

## <a id="evaluation-on-group"></a>Evaluation on group
